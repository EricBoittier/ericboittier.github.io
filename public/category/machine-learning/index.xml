<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning | Eric Boittier</title><link>https://www.ericboittier.github.io/category/machine-learning/</link><atom:link href="https://www.ericboittier.github.io/category/machine-learning/index.xml" rel="self" type="application/rss+xml"/><description>machine learning</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 01 Aug 2022 00:00:00 +0000</lastBuildDate><image><url>https://www.ericboittier.github.io/media/icon_hu9ac327d6012d36714959b8b60a0f0d52_7608_512x512_fill_lanczos_center_3.png</url><title>machine learning</title><link>https://www.ericboittier.github.io/category/machine-learning/</link></image><item><title>Notes on Baysian Optmization</title><link>https://www.ericboittier.github.io/post/notes/</link><pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.ericboittier.github.io/post/notes/</guid><description>&lt;h2 id="surrogate-models-to-the-rescue">Surrogate Models to the Rescue&lt;/h2>
&lt;p>If you have a cost function that is too expensive to evaluate, you should check out Bayesian Optimization.&lt;/p>
&lt;p>The idea is to use a surrogate model to approximate the cost function and then use this model to find the best point to evaluate next.&lt;/p>
&lt;p>The most common surrogate model is a Gaussian Process (GP), which is a distribution over functions. The GP is defined by its mean function $m(x)$ and covariance function $k(x, x&amp;rsquo;)$:&lt;/p>
&lt;p>$$f(x) \sim \mathcal{GP}(m(x), k(x, x&amp;rsquo;))$$&lt;/p>
&lt;p>The GP is updated with the new data point and then used to find the next point to evaluate. This is typically done by maximizing an acquisition function, such as the Expected Improvement (EI):&lt;/p>
&lt;p>$$EI(x) = \mathbb{E}[\max(f(x) - f(x^+), 0)]$$&lt;/p>
&lt;p>where $f(x^+)$ is the current best observed value.&lt;/p></description></item></channel></rss>