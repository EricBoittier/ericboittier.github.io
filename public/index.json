[{"authors":null,"categories":null,"content":"A blog about machine learning for the physical sciences, with a focus on molecular dynamics simulations.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"26f7143ab6a67e9866e2f9d6bd18a253","permalink":"https://ericboittier.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"A blog about machine learning for the physical sciences, with a focus on molecular dynamics simulations.","tags":null,"title":"Eric Boittier","type":"authors"},{"authors":["Eric Boittier","Kai Toepfer","Mike Devereux","Markus Meuwly"],"categories":null,"content":"","date":1719792e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719792e3,"objectID":"08d60dc4231dc8a4f1aceded51d598ab","permalink":"https://ericboittier.github.io/publication/kernelmdcm/","publishdate":"2024-01-01T00:00:00Z","relpermalink":"/publication/kernelmdcm/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Kernel-based Minimal Distributed Charges: A Conformationally Dependent ESP-Model for Molecular Simulations","type":"publication"},{"authors":["Eric Boittier"],"categories":["generative"],"content":"Flux is a generative diffusion model from Blackforest Labs. Diffusion is a process by which particles spread out from a high concentration to a low concentration. The model uses a series of transformations to generate images, starting from a simple noise vector and gradually generating an image over some number of steps. Here is some output of the model:\nDiffusion-kit provides a simple interface to run the model on a macbook,\ndiffusionkit-cli --prompt \u0026#34;prompt\u0026#34; \\ --steps 3 --output-path \u0026#34;featured.png\u0026#34; And in python:\nfrom diffusionkit.mlx import FluxPipeline pipeline = FluxPipeline( shift=1.0, model_version=\u0026#34;argmaxinc/mlx-FLUX.1-schnell\u0026#34;, low_memory_mode=True, a16=True, w16=True, ) HEIGHT = 512 WIDTH = 512 NUM_STEPS = 4 # 4 for FLUX.1-schnell, 50 for SD3 CFG_WEIGHT = 0. # for FLUX.1-schnell, 5. for SD3 image, _ = pipeline.generate_image( \u0026#34;a photo of a cat\u0026#34;, cfg_weight=CFG_WEIGHT, num_steps=NUM_STEPS, latent_size=(HEIGHT // 8, WIDTH // 8), ) image.save(\u0026#34;image.png\u0026#34;) Quite impressive. I thought diffusion would require more steps. In thermodynamics, diffusion is a slow process, the long-time limit of how much a system can change. Certainly, something exciting is going on under the hood. The model is based on an architecture published on “Scaling Rectified Flow Transformers for High-Resolution Image Synthesis” by Stability AI (paper).\nLet’s look a bit deeper in the code:\nThe text is transformed into an embedding, which is used to condition the image generation. The function ’encode_text’ is used to encode the text into an embedding.\nconditioning, pooled_conditioning = self.encode_text( text, cfg_weight, negative_text ) mx.eval(conditioning) mx.eval(pooled_conditioning) The diffusion steps take place inside the FluxPipeline class, in the generate_image method. The specific function inside this method is:\ndef denoise_latents( self, conditioning, pooled_conditioning, num_steps: int = 2, cfg_weight: float = 0.0, latent_size: Tuple[int] = (64, 64), seed=None, image_path: Optional[str] = None, denoise: float = 1.0, ): # Set the PRNG state seed = int(time.time()) if seed is None else seed logger.info(f\u0026#34;Seed: {seed}\u0026#34;) mx.random.seed(seed) x_T = self.get_empty_latent(*latent_size) if image_path is None: denoise = 1.0 else: x_T = self.encode_image_to_latents(image_path, seed=seed) x_T = self.latent_format.process_in(x_T) noise = self.get_noise(seed, x_T) sigmas = self.get_sigmas(self.sampler, num_steps) sigmas = sigmas[int(num_steps * (1 - denoise)) :] extra_args = { \u0026#34;conditioning\u0026#34;: conditioning, \u0026#34;cfg_weight\u0026#34;: cfg_weight, \u0026#34;pooled_conditioning\u0026#34;: pooled_conditioning, } noise_scaled = self.sampler.noise_scaling( sigmas[0], noise, x_T, self.max_denoise(sigmas) ) latent, iter_time = sample_euler( CFGDenoiser(self), noise_scaled, sigmas, extra_args=extra_args ) latent = self.latent_format.process_out(latent) return latent, iter_time The function ‘decode_latents_to_image’ is used to decode the latent representation to an image. It calls the decoder and then the clip module to get the final image. The code:\ndef decode_latents_to_image(self, x_t): x = self.decoder(x_t) x = mx.clip(x / 2 + 0.5, 0, 1) return x The architecture class MMDiT(nn.Module): def __init__(self, config: MMDiTConfig): super().__init__() self.config = config # Input adapters and embeddings self.x_embedder = LatentImageAdapter(config) if config.pos_embed_type == PositionalEncoding.LearnedInputEmbedding: self.x_pos_embedder = LatentImagePositionalEmbedding(config) self.pre_sdpa_rope = nn.Identity() elif config.pos_embed_type == PositionalEncoding.PreSDPARope: self.pre_sdpa_rope = RoPE( theta=10000, axes_dim=config.rope_axes_dim, ) else: raise ValueError( f\u0026#34;Unsupported positional encoding type: {config.pos_embed_type}\u0026#34; ) self.y_embedder = PooledTextEmbeddingAdapter(config) self.t_embedder = TimestepAdapter(config) self.context_embedder = nn.Linear( config.token_level_text_embed_dim, config.hidden_size, ) self.multimodal_transformer_blocks = [ MultiModalTransformerBlock( config, skip_text_post_sdpa=(i == config.depth_multimodal - 1) and (config.depth_unified \u0026lt; 1), ) for i in range(config.depth_multimodal) ] if config.depth_unified \u0026gt; 0: self.unified_transformer_blocks = [ UnifiedTransformerBlock(config) for _ in range(config.depth_unified) ] self.final_layer = FinalLayer(config) The forward pass: def __call__( self, latent_image_embeddings: mx.array, token_level_text_embeddings: mx.array, timestep: mx.array, ) -\u0026gt; mx.array: batch, latent_height, latent_width, _ = latent_image_embeddings.shape token_level_text_embeddings = self.context_embedder(token_level_text_embeddings) if hasattr(self, \u0026#34;x_pos_embedder\u0026#34;): latent_image_embeddings = self.x_embedder( latent_image_embeddings ) + self.x_pos_embedder(latent_image_embeddings) else: latent_image_embeddings = self.x_embedder(latent_image_embeddings) latent_image_embeddings = latent_image_embeddings.reshape( batch, -1, 1, self.config.hidden_size ) if self.config.pos_embed_type == PositionalEncoding.PreSDPARope: …","date":1692230400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692230400,"objectID":"2a224d24bb013949c70a0e8ee67a57b7","permalink":"https://ericboittier.github.io/post/fluxschnell/","publishdate":"2023-08-17T00:00:00Z","relpermalink":"/post/fluxschnell/","section":"post","summary":"Generative AI on a macbook.","tags":["code","machinelearning"],"title":"Flux.1","type":"post"},{"authors":["Eric Boittier"],"categories":["how-to","juptyer"],"content":"The following post was made by creating a Jupyter notebook and converting it to a blog post, using the nbconvert tool.\njupyter nbconvert --to markdown Test\\ Notebook\\ Blog\\ Post.ipynb --NbConvertApp.output_files_dir=. The command above will convert the notebook to Markdown and save it in the same directory as the notebook. Adding the usual Hugo front matter to the markdown file will allow it to be rendered as a blog post. Assuming you already have an index.md file with front matter, something like:\ncat \u0026#39;Test Notebook Blog Post.md\u0026#39; | tee -a index.md …will do the trick!\nTest Notebook Blog Post import matplotlib.pyplot as plt import numpy as np Let’s do something a bit random!\nX = np.random.rand(100).reshape(10,10) plt.imshow(X) \u0026lt;matplotlib.image.AxesImage at 0x1248bd4b0\u0026gt; ","date":1692230400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692230400,"objectID":"07f2dc263978e523cb748aff416f69da","permalink":"https://ericboittier.github.io/post/test-notebook/","publishdate":"2023-08-17T00:00:00Z","relpermalink":"/post/test-notebook/","section":"post","summary":"Automatically add notebooks to the blog?!","tags":["code","machinelearning"],"title":"From Juptyer to Blog","type":"post"},{"authors":["Eric Boittier"],"categories":["optimization","programming"],"content":"All About Fortran What is Fortran? Fortran is a dinosaur code language. It was released around 65 years ago (date of writing) by John Backus and IBM for electric computing machines powered by the fossilized remains of dinosaurs who lived around 65 million years ago.\n‘Too lazy’ to write assembly, Backus wrote this compiled imperative language to save himself time when composing complicated mathematical formulas, giving rise to the ‘Formula Translation’ language or FORTRAN. Nowadays, FORTRAN is considered too verbose by modern programming standards. Although much slower, Python might be considered the new Formula Translation language. Routines like the Fast Fourier Transform have been reduced to one line (np.fft()), where the number of lines of pure FORTRAN and assembly code needed are around 1 to 2 orders of magnitude longer, respectively.\nWhy Fortran? Fortran is fast. Many legacy applications rely on Fortran for reasons related to speed and compatibility.\nThe Good Type of Profiling How can we test the speed of our code? Profiling is a strategy to monitor the performance of one’s code. Results often show the time spent in individual routines, the number of calls, as well as the order in which routines have been accessed.\nProfiling Fortran with gprof Fortran must first be compiled with the following, additional flags:\n... -pg fcheck=bounds,mem The ‘fcheck’ option allows the compiler to produce warnings for attempts at accessing undefined memory, etc.\nOnce compiled, run your code as usual:\n./yourcode A file named ‘gmon.out’ will be created in the current directory. To see the results of the profiling\ngprof -l -b ./yourcode \u0026gt; gprof.log The -g and -l flags in the compilation and profiling steps, respectively, allow for a line by line analysis of time spent during computation. Without these options, the profiler will show total time spent in each subroutine.\n","date":1660694400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660694400,"objectID":"73f54d34305b16238c06c5395b9d0e5c","permalink":"https://ericboittier.github.io/post/profiling-fortan/","publishdate":"2022-08-17T00:00:00Z","relpermalink":"/post/profiling-fortan/","section":"post","summary":"Fortan go \"brrr\"... but can we make it go faster? Profiling code is the best way to improve efficiency. Here you'll find a short explanation on how to do this in Fortran.","tags":["code","fortran"],"title":"Fortran is fast. Profile your code to make it faster!","type":"post"},{"authors":["Eric Boittier"],"categories":["optimization","machine learning"],"content":"Surrogate Models to the Rescue If you have a cost function that is too expensive to evaluate, you should check out Bayesian Optimization.\nThe idea is to use a surrogate model to approximate the cost function and then use this model to find the best point to evaluate next.\nThe most common surrogate model is a Gaussian Process (GP), which is a distribution over functions. The GP is defined by its mean function $m(x)$ and covariance function $k(x, x’)$:\n$$f(x) \\sim \\mathcal{GP}(m(x), k(x, x’))$$\nThe GP is updated with the new data point and then used to find the next point to evaluate. This is typically done by maximizing an acquisition function, such as the Expected Improvement (EI):\n$$EI(x) = \\mathbb{E}[\\max(f(x) - f(x^+), 0)]$$\nwhere $f(x^+)$ is the current best observed value.\n","date":1659312e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659312e3,"objectID":"5ac6d4b5530eb165391f308c8ccc0161","permalink":"https://ericboittier.github.io/post/notes/","publishdate":"2022-08-01T00:00:00Z","relpermalink":"/post/notes/","section":"post","summary":"If your cost function is too expensive to evaluate, you should check this out!","tags":["code","machinelearning"],"title":"Notes on Baysian Optmization","type":"post"},{"authors":["Eric Boittier","Mike Devereux","Markus Meuwly"],"categories":null,"content":"","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656633600,"objectID":"5ed36c6bf93fa6146b84d875f1e489a5","permalink":"https://ericboittier.github.io/publication/fmdcm/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/fmdcm/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Molecular Dynamics with Conformationally Dependent, Distributed Charges","type":"publication"},{"authors":["Luis Itza Vazquez-Salazar","Eric Boittier","Oliver Unke","Markus Meuwly"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"e4e4c4dd4d5cdd556c6e152797c47127","permalink":"https://ericboittier.github.io/publication/mldatabase/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/mldatabase/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Impact of the Characteristics of Quantum Chemical Databases on Machine Learning Prediction of Tautomerization Energies","type":"publication"},{"authors":["Silvan Kaeser","Eric Boittier","Meenu Upadhyay","Marky Meuwly"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"7f7882bb6ebb42cec6b4ceef7181a188","permalink":"https://ericboittier.github.io/publication/mlccsdt/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/mlccsdt/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Transfer Learning to CCSD(T): Accurate Anharmonic Frequencies from Machine Learning Models","type":"publication"},{"authors":["Eric Boittier","Yat Yin Tang","McKenna E Buckley","Zachariah P Schuurs","Derek J Richard","Neha S Gandhi"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"efcc947c47fa7bb4dd2c7318d3dc45ce","permalink":"https://ericboittier.github.io/publication/docking/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/docking/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Assessing Molecular Docking Tools to Guide Targeted Drug Discovery of CD38 Inhibitors","type":"publication"},{"authors":["Eric Boittier","Jed M Burns","Neha S Gandhi","Vito Ferro"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"d4031d9883199f8c441d543e9376d9cb","permalink":"https://ericboittier.github.io/publication/glycotorch/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/glycotorch/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"GlycoTorch Vina: Docking Designed and Tested for Glycosaminoglycans","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://ericboittier.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1530144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530144e3,"objectID":"049997142420607bd66b5e7cac396e28","permalink":"https://ericboittier.github.io/arxiv-tinder/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/arxiv-tinder/","section":"","summary":"","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"","date":1530144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530144e3,"objectID":"70e3e0af5a872f3d835743572921da47","permalink":"https://ericboittier.github.io/all-posts/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/all-posts/","section":"","summary":"A list of all the blog posts.","tags":null,"title":"All Blog Posts","type":"page"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://ericboittier.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"}]